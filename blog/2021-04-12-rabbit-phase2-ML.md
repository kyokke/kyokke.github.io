@def title = "ラビットチャレンジ: Phase.2 機械学習"
@def author = "kyokke" 
@def tags = [ "Deep-Learning", "Rabbit-Challenge" ]


# ラビットチャレンジ: Phase.2 機械学習 [執筆途中]

本ページはラビットチャレンジの、
Phase.2 機械学習のレポート提出を兼ねた受講記録です。
提出指示に対して、下記の方針でまとめました

1. 動画講義の要点まとめ
   - 自分がその手法を思い出して実装するのに必要な最低限の情報 (モデル定義・評価関数・解放の着想があれば十分かなぁ.. )
   - 講義で口頭補足されたトピックなどあれば。

2. 実装演習(ハンズオン実行)
   - 基本的には scikit-learn のノートの内容に準じる(より実践的?っぽいので)
     - 対応する numpy実装を見て、sikit-learn側に応用できそうなことがあればやってみる (コアアルゴリズム部分を numpy 実装に置き換えてみるとか) 
     - その他パラメータのチューニングなど。その他、何か追加でやりたくなったら、適当に追加。
   - ノートブックを jupyter nbconvert で markdown に変換しその抜粋を掲載
     - markdown /コード/出力 のそれぞれに関して、blog上での表示を考慮してあとから微調整を行う
     - 手法に関する一般的な説明・数式展開などは、要点のまとめ側に移動する場合も　

## 目次
\toc

## 各論前の講義内容　[課題外]

 - プロローグ ( なぜ 非ディープラーニングの機械学習の勉強をするのか? )
   - 数学的な背景を元にした機械学習の基礎を抑えていないエンジニアは、フレームワークを使って機械学習モデルを組める「程度」の人材にしかならない

   - 機械学習のモデリングプロセスをしっかりと抑えることが重要
     1. 問題設定
        - 最終的な使われ方をイメージしよう
        - 必ずしも機械学習を使う必要は無く、ルールベースで解けるならそっちの方が楽
          - 技術的負債になりやすい
            - 自分が開発した技術を運用チームに移管するとして、移管先に専門知識を持った人間がいなければSLA(Service Level Agreement)を担保できない
          - テストしにくい・考慮すべきことが多い
          - データ集めるの大変
     2. データ選定
        - GIGO(garbage in garbage out) = ゴミを突っ込んだらゴミが出てくる
          - ex. 集めたデータに(意図しない)バイアスがかかっているなど。
     3. データの前処理
        - 開発時間の殆どは、このプロセスに費やされるといっても過言でない
        - 実務経験がモノをいうところ。練習のチャンスがない人は、kaggleなどやるといい
     4. モデルの選定
        - ディープラーニング(で扱われるモデル)も、機械学習モデルの一部に過ぎず、このプロセスの具体的な作業が異なるだけ
     5. モデルパラメータの決定
     6. モデルの評価

 - ルールベースモデルと機械学習モデル
   - 技術者として、機械学習とは?と聞かれたら何らかの形で答えられるようになっておくこと
     - 講師の体感では、機械学習ってなに? と聞かれるよりも、人工知能って何? と聞かれることの方が多いらしい 

## 線形回帰モデル [提出対象]

### 動画講義メモ(要点のまとめ)

 - 回帰問題 = 入力から出力を予測する問題。線形回帰は、回帰式が線形。
   - 線形回帰モデルの形 (線形とは?) 
     - ざっくり説明 = 入出力が比例関係である (直線・平面・超平面)
     - $ y = w_0 + \sum_{i=1}^{n-1} w_i x_i $
       - $ = \sum_{i=0}^{n-1} w_i x_i $　
       - $ = \bm{w}^T \bm{x} $  ただし $ \bm{w}^T = (w_0, w_1, ... , w_{n-1})$, $ \bm{x}^T = (1, x_1, ... , x_{n-1})$ 
     - 記法としては ベクトルが便利、訳わからなったら sigma 記法にする
       - このベクトル/行列と 要素ごとの記法の行き来ができることがポイント
       - この後の記述とあわせて係数は $w$ にした
    - 出力について
      - 連続値とスライドに書かれているが、離散値でもいい
        - 例: 諸条件から、競馬の順位を予想する
          - cf. "vapnik の原理" には反する
            - 順位 = 大小関係 がわかるだけでいいのに、もっと難しい回帰問題を解くべきではないという話。
            - [論文](https://www.ism.ac.jp/editsec/toukei/pdf/58-2-141.pdf)
      - スカラーと書いてあるが、多次元のベクトルにしてもいい(マルチタスク学習など)
      - データ分割・学習
        - 未知のデータに対する予測精度をあげたいので、テスト用のデータと、学習用のデータは分ける
        - 最尤法による解とMSEの最小化は等価と書いてあったが、それは誤差を確率変数としたとき、これが正規分布に従う場合では? (他の分布なら、別の解でてくる場合もあるよね?) 
    - 誤差について
      - 必ずしも偶発的な誤差だけではなく、モデル化誤差もある
        - y = 来店者数、x = 気温 で予測ができる? いや、曜日にも影響する。このとき、曜日の項の影響は誤差になる
    - 未知数の数と方程式の数について
      - 今、重みw は m+1 次元なので、基本的には、 m+1 以上の方程式がないと厳しい
        - データの方が少ないケースを扱う手法もあるが、それは advanced 
        - DLの場合パラメータがたくさんあるので、データが必要
    - パラメータ推定方法 : 最小二乗法
      - $ \mathrm{MSE_{train}} = \frac{1}{n} \sum_{i=1}^{n_{train}} (\hat{y_i}^{(train)}-y_i^{(train)})^2 = \sum \epsilon^2 :=  J(w) $
        - MSE = mean square error
      - これをパラメータについて微分して、勾配が0になる点を求める
        - $ \bm{\hat{w}}= (X^T X) ^{-1} X^T \bm{y} $  : (train) は省略
          - $\bm{y}$ に 一般化逆行列をかけた形
        - 必ずしも誤差関数として二乗誤差は最適ではないことに注意
          - 基本的にハズレ値の存在にかなり弱くなる
          - Huber loss, Tukey loss とか　を使うとハズレ値に強くなる
       - よく使う ベクトルの微分の形
         - $ \frac{\partial}{\partial \bm{w}} \bm{w} ^T \bm{x} = x$
         - $ \frac{\partial}{\partial \bm{w}} \bm{w}^T A \bm{w} = (A+A^T) \bm{x} = 2A\bm{x}$ (Aが対称行列のとき)
         - 参考図書: Matrix Cook Book 

 - ハンズオンに関するコメント
   - 全部の説明変数を使う必要はないし、使うべきではないことがある
    - 12番目の "アフリカ系アメリカ人居住者の割合" など
   - 現実のデータセットを扱う上では、よくデータをみる必要がある
     - 得られたデータの中に使用すべきでないもの(ハズレ値など) があるかもしれない
     - 要約統計量などを適宜活用
     - pandas で 12行目まで観察 ( 頭の数行みて、怪しい所があったから。最初の5行 CHAS全部0じゃね?)
   - エイヤで学習すると、マイナスの価格が出てしまった件
     - こういう現象が出た時点でおかしい、と気付かなければいけない
     - 何がダメだったんだろう -> 1部屋のケースなどがデータに入ってないんだろうな
       - 外挿問題にDLは基本的には弱い 5~10部屋の範囲のデータから学習したとき、11部屋, 2部屋の時の予測は上手く行かない
   - scikit-learn や tensorflow で動かすのは小学生でもできる。なんとなく動かすんじゃなくて、数式に対する理解を持つこと
   - 多重回帰の場合も試しに実行してみてね
     - 学習されたモデルを評価する
      - 部屋を増やしてみる(価格増えるはず)
      - 犯罪率増やしてみる(価格下がるはず)

\textinput{skl_regression.md}


## 非線形回帰 [提出対象]

### 動画講義メモ(要点のまとめ)

- モデルの形
  - 線形回帰 $ y = \sum w_i x_i $ で、$ x_i $ の代わりに 非線形関数 $\phi_i (\bm{x})$ を使う。
    - $\phi_0 = 1, w_0 =1 $
    - $ w $ については線形 (linear-in-parameter) のまま
    - -> 二乗誤差に対する解としてパラメータは求められるってことね
    - 旧動画では、これを基底関数法と呼んでいた
- 未学習(underfitting)・過学習(overfitting)について
  - 多項式近似の例:  4次以上はフィッティング具合ほとんどかわらない
    - 左のグラフ(1,2次ぐらい) -> 未学習
    - 真ん中(4次ぐらい) -> 望ましい状態
    - 右のグラフ(もっと次数をあげた) -> 過学習
  - 訓練誤差とテスト誤差を比較することで、判断ができる
    - cf. 2018年の DL 論文で、過学習可と思いきや、ずっと学習続けてると、またロスが下がり始める現象が報告されていた(double descent)
- 過学習の対策
  1. 学習データを増やす
  2. 不要な基底関数を削除して表現力を抑止 
    - 情報量基準などを使う
    - 愚直にやると、組合せ爆発を起こすので大変
  3. 正則化法を利用して表現力を抑止
    - モデルの複雑さに伴って、その値が大きくなるようなペナルティを関数に課す
      - 今回の場合は重みパラメータの大きさ
        - 4次まで誤差を十分小さくできており、7次以上の項による誤差低減効果はほぼない。この状態で、正則化を行えば、7次以上の重みパラネータが小さく抑えられるはず。
      - $ min. \  MSE + \lambda R(\bm{w}) $ を解けば良い。( $R(\bm{w})$ が正則化項)
        - KKT条件によって、$ min. \ \mathrm{MSE} \ s.t. \ R(\bm{w}) \le r $ を一つの目的関数の最小化問題に変換
          - 今回の場合、必ずしも上記不等式制約を満たす必要はない(なるべく小さくすればいいだけ)なので上記の議論で問題ない
          - $r$ は $\bm{w}$ によらないので目的関数からは削除されてる 
     - 正則化項の例
       - Ridge推定量　- 正則化項 にL2ノルムを使う (パラメータを0に近づける)
       - Lasso推定量  - 正則化項 にL1ノルムを使う (スパース推定) 
     - 正則化項にかかるパラメータは hyper parameter 　
 - モデル選択
    - 評価するときには、学習に使ってないデータ(検証データ)に対する評価値を見る
    - ホールドアウト法
      - 学習に使うデータと、検証に使うデータを固定する
        - 大量にデータが手元にあるときはこれをやることがおおい
      - 注意点 : 
        - 検証用データに "はずれ値"が入ってしまうと、はずれ値にフィットするモデルが選ばれる、ということが起きる
    - 交差検証法 (クロスバリデーション) 
      - データを学習用と評価用に分割するのだが、その分割の仕方をローテーションする。例えば、5分割したうちの1つが検証、残りが学習、みたいな
      - 1つのモデルに対して、 5回の評価が行われる。精度の平均値 CV値で評価する
      - Q&A 精度ってどうやって計算するの? -> 基本的には 学習時のloss をそのまま使う
      - 基本的には交差検証法の方の値を報告する
 - ハイパーパラメータの調整をどうしよう? という話　
   - グリッドサーチは 実装の練習はしてもいいと思うけど、実践的にはあまり使わない。
   - ベイズ最適化(BO)が最近だとよく使われる? 
     - PFN の optunaなど

\textinput{skl_nonlinear_regression.md}

## ロジスティック回帰
### 動画講義メモ(要点のまとめ)

- 参考: google AI blog の記事
  - DNNじゃなくてあえてlogistic 回帰使いました
  - [using ML to Predict Parking Difficulty (2017年 2月)](https://ai.googleblog.com/2017/02/using-machine-learning-to-predict.html)

 - 分類問題に対するアプローチ
    1. 識別的アプローチ
      - $ p(C_k | x ) $ を直接モデル化する方法
        - logistic 回帰は、これ。
      - 識別関数をつかう方法
        - $f(x) >  0$ なら　$C = 1$,  $f(x) < 0$ なら　$C = 0$ みたいな
        - SVMはこれ
    2. 生成的アプローチ
      - $ p(C_k) $ と $ P(x|C_k)$ を model化して、その後 Bayesの定理を用いて、$ p(C_k | x ) $ を求める
        - ハズレ値の検出をもとめたり、生成モデルをつくれたりする
      - ロジスティック回帰での使い方
        - 一般に実数全体をとり得る入力の線形結合に sigmoid 関数をかけて値域を0~1にすることで確率とみなせるようにしている
        - 確率が0.5以上ならば、1, 未満なら、0と予測
      - なんでわざわざ確率にする? -> 判断の保留などが可能
        - 識別関数だと、識別結果をそのまま使用するしかない
 - 最尤推定: ベルヌーイ分布のパラメータ推定
    - データ-> ベールヌーイ分布の計算
      - 1回の試行 $ P(y) = p^y (1-p)^{1-y} $
      - n回の試行で、$y_1,..,y_n$ が同時に起こる確率 $P(y_1,..,y_n;p)=  \prod_{i=0}^{i=n-1} p^{y_i} (1-p)^{1-y_i} $
    - パラメータである p を データ $y_1,..,y_n$ から推定したい。
      - pを色々変えて、$y_1,..,y_n$ が得られる確率が最大になるような $p$ を求める->最尤推定
    - ロジスティク回帰モデルの最尤推定
      - $P(Y=y_1 | \bm{x}_1 ) =p_1^{y_1} (1-p_1)^{1-y_1} $
        - 確率はロジスティック回帰 $ p_1 = \sigma(\bm{w}^T \bm{x}_1)$ で計算できるので、尤度が最大になる $ \bm{w} $ を探す問題
  - 更新式の導出: ひたすら微分。もう何度もやったのでここでは省略. 
    - 対数尤度を使う理由
      - 微分の計算が簡単ってのは、正直どうでもいい (それならそう書かないでくれ)
      - 尤度 : 確率を何度も掛け算する -> 桁落ちの可能性
    - 微分のchane ルールを理解して使いこなすことが重要
 - 確率的勾配法
   - Iteration によってデータを入れ替えることで、パラメータ更新の勾配方向をある程度不規則にして、初期値依存制を低減する効果を狙う
   - ただし、ロジスティック回帰なら単峰制なので局所最適に陥る心配はないのだが
   - [p.70 の参考文献](http://ibis.t.u-tokyo.ac.jp/suzuki/lecture/2018/kyoto/Kyoto_02.pdf)
     - 層を深くすること近似できる関数の自由度がどう増えていくか? とか興味深いがそもそも、どんな意図で貼られているんだろう?
 - モデルの評価
   - 混合行列でマトリックスを使って整理.
     - 行 = モデルの予測結果の Positive/Negative
     - 列 = 検証データの Positive/Negative 
     - 対角成分が 正解(True), 非対角成分が不正解(False)となる
   - FalsePotsitve と FalseNegativeとを分けて評価する
     - Link: http://ibisforest.org/index.php?F%E5%80%A4
     - 検証データ中の Posi/Nega のバランスが取れてないとき何をみてるかわからなくなる
       - 間違い方によって何が嫌かが違う
     - 再現率(Recall): Positiveデータに対する正答率 = TP/(TP+FN)
       - 過剰検出を許容して、ヌケモレのなさを重視する評価
     - 適合率(Precision): モデルがPositiveと予測したものに対する正答率 = TP/(TP+FP)
       - 見逃しを許容して、慎重な検出を評価する
     - F値 : Recall と Precision の調和平均
       - どっちにも振れない微妙なタスクにつかう?
     - 現場でよくやるのは、上記3つ全部並べておくこと 

\textinput{skl_logistic_regression.md}


## 主成分分析 (PCA) 

### 動画講義メモ(要点のまとめ)

\textinput{np_regression.md}

## k-nn/means 法 (レポート提出課題の "アルゴリズム" の単元に該当?)

### 動画講義メモ(要点のまとめ)

 - k近傍法  
   - 分類問題の機械学習手法
   - 最近傍のデータをk個撮ってきて、それらがもっとも多く所属するクラスに識別
     - ということは、2クラス分類なら、k は奇数にするということか
   - k はハイパパラメータ
     - k を大きくすると決定境界がなめらかになる(多すぎると過学習気味)
 - k-平均法(k-means) 
   - 教師なし学習, クラスタリングを行う手法
   - アルゴリズム
      1. 各クラスタについて、中心の初期値を設定
      2. 各データ点に対して、各クラスタ中心との距離を計算し、最も距離が近いクラスタを割り当てる
      3. 各クラスたの平均ベクトルを計算しあらたな中心とする
      4. 収束するまで2,3の処理を繰り返す
   - 初期値重要
     - 初期値を変えるとクラスタリング結果も変わりうる
       - 初期値が離れていたほうがいい?
       - cf. k-means++ (試験でも出たらしい)
     - クラスタ数 k を変えてももちろん結果が変わる

\textinput{skl_kmeans.md}


## サポートベクターマシン(SVM)

### 動画講義メモ(要点のまとめ)

\textinput{np_regression.md}

## 取り組み概要 & 感想

### 取り組みの記録

- 3/31, 4/1: まずはざっと新しい動画を視聴(1.5倍速)しながらメモをとり・微分計算。基本的に動画を途中でストップすることはなかった。約200分で完了。まぁ、問題なさそうだなぁ。という感触だけ得る。

- 4/1~28 : しばらく塩漬け状態.. (GTC21の聴講などをしていたので)

- 4/29 : ハンズオンの実行環境の構築。Collaborately はセル実行のレスポンスが遅いのでローカルに環境を整える。win10上に pyenv + poetry でを仮想環境を作る。30分程度。

- 4/30-5/1 : 線形回帰 旧動画の方をみながらハンズオン。新旧動画をみながら残したメモを適当に要点まとめとしてblog記事にする。その後 ハンズオンのノートブックファイルを markdown 化し、課題提出用blogの記事ty中にinclude。ハンズオンが 45分, 要点まとめや記事の整形が 1h. 

- 5/1 : 非線形回帰。旧動画をみながら、新動画をみたときのメモと見比べていくつかコメント追加し、要点まとめ。その後、ハンズオンを実行。scikit-learn で RBFカーネルといったときには何をさすのか? SVRってなんだ? など調べていたらすこし時間をくった。合計 3h。

- 5/2 : ロジスティック回帰・k-nn/means 

- 5/3 : SVM について同様に

- 5/3 : ステージテスト

合計

のところをかなりすっ飛ばしていた印象だったので、ハンズオンを実行・コードを追いかけながら、動画を見てみる。 xx  分　
  -  

前半
12+4+2+3+2+2.5+2+2+2.5+2+2+2+2+2+3+2+1+3+3+4　= 60分
後半
12+4+2+3+2+2.5+2+2+2.5+2+2+2+2+2+3+2+1+3+3+4 = 78分
100分くらい


動画講義の最新版・旧版についてだが、

最新動画はハンズオンの部分をかなりすっ飛ばしていた印象だったので、旧動画の方も見てみる。

実行・編集したノートブックは以下のレポジトリで管理 -> 

ハンズオンの部分もとりあえず見てしまったが、かなりすっ飛ばしていた印象。

新しい動画の方はハンズオンについてはかなりすっ飛ばしていたので、とりあえず見るだけ。

ハンズオン

線形代数は 2/10-15 の間に少しずつ消化。それからしばらく、勤め先の業務の忙しさにかまけて1ヶ月計画的に放置したが、その後 3/16-18, 22 に統計学の講義動画を試聴。内容に応じて 1.2-1.5倍速で再生しつつ、基本的には動画を止めずにメモを箇条書きレベルでまとめていった。合計 5h 程度。

3/28, 29に動画講義のまとめを行う。基本的には、動画視聴中の箇条書きメモを markdown として整形しつつ、読み返して講義の内容を思い出せないところがあれば、少し見返して補った。合計 2h 程度。

3/30。演習は 20分、ステージテストは 35分 なので 合計約 1h。スタートテストと同じく、Python のインタプリタを起動して検算できるようにしつつも、紙・鉛筆も用意して、適宜使いやすい方を使う。

以上、合計 8h で終了。

演習については、線形代数の四則演算をのぞけば、
用語の定義自体を問題文で説明した上でシンプルな問に答えさせる問題や、用語の定義自体の理解を問う問題が大半だった。実力試し・理解度確認のための演習というより、講義動画の理解を助けるものという印象。例えば、自己情報量やエントロピーの説明は、講義と若干違う説明の仕方がされており、個人的には演習の説明のほうがすっきり理解できる。講義動画見ながら該当箇所の演習をやればよかったな、と思う。(次からそうしよう)


## 計画の見直し (2021/04/30 時点)

元々の計画では、3月中にステージ2まで終わらせる予定だったので、計画を下記のように見直した。

 - ~2021/2/15  : スタートテスト (2021/02/07完了)
 - ~2021/3/30  : ステージ1      (2021/03/30完了)
 - ~2021/4/18  : ステージ2      (2021/04/30完了)
 - ~2021/5/09  : ステージ3 
 - ~2021/6/06  : ステージ4 
 - ~2021/6/27  : 復習 -> 修了テスト 
 - ~2021/7/15  : Eもぎライト -> 今後の計画具体化 
 - ~2021/7/30  : シラバスの未習箇所の学習 
 - ~2021/8/26  : 全体の復習
 - 2021/8/27,28: E資格 受験 

ステージ2,3,4 のボリュームが読めないので、上記を少し前倒しですすめられるといいなとは思っている。

ラビットチャレンジの修了が後ろ倒しになったが、最近E資格を取得された方の話を聞く限り、修了後の勉強期間にそこまで長い時間を設けなくて良さそうな印象だったので問題ないと考える。